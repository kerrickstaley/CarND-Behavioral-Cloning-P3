{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import numpy.random\n",
    "import random\n",
    "from collections import namedtuple\n",
    "import tensorflow\n",
    "\n",
    "SIDE_CAMERA_OFFSET = 0.3\n",
    "\n",
    "\n",
    "class DataLoader:\n",
    "    \n",
    "    FrameRecord = namedtuple('FrameRecord', ['center_path', 'left_path', 'right_path', 'angle', 'dup_factor'])\n",
    "    \n",
    "    def __init__(\n",
    "            self, data_dirs_and_dup_factors):\n",
    "        self.data_dirs_and_dup_factors = data_dirs_and_dup_factors\n",
    "        \n",
    "        self.frame_records = []\n",
    "        for d, dup_factor in self.data_dirs_and_dup_factors:\n",
    "            with open(os.path.join(d, 'driving_log.csv')) as inf:\n",
    "                for line in csv.reader(inf):\n",
    "                    paths = line[:3]\n",
    "                    paths = [os.path.join(d, 'IMG', p.split('/')[-1]) for p in paths]\n",
    "                    angle = float(line[3])\n",
    "                    self.frame_records.append(self.FrameRecord(*(paths + [angle, dup_factor])))\n",
    "\n",
    "    @staticmethod\n",
    "    def fix_img_path(path):\n",
    "        fname = path.split('/')[-1]\n",
    "        return os.path.join(os.getcwd(), 'data', 'IMG', fname)\n",
    "    \n",
    "    @staticmethod\n",
    "    def all_img_paths(path):\n",
    "        center = fix_img_path(path)\n",
    "        left = 'left'.join(center.rsplit('center', 1))\n",
    "        right = 'right'.join(center.rsplit('right', 1))\n",
    "        \n",
    "        return center, left, right\n",
    "    \n",
    "    def load_all_data(self):\n",
    "        rv_x = []\n",
    "        rv_y = []\n",
    "        for r in self.frame_records:\n",
    "            offsets = [0, SIDE_CAMERA_OFFSET, -SIDE_CAMERA_OFFSET]\n",
    "            for path, offset in zip(r[:3], offsets):\n",
    "                imdata = cv2.imread(path)\n",
    "                angle = r.angle + offset\n",
    "                \n",
    "                for i in range(r.dup_factor):\n",
    "                    rv_x.append(imdata)\n",
    "                    rv_y.append(angle)\n",
    "                    # also append reversed data\n",
    "                    rv_x.append(imdata[:,::-1,:])\n",
    "                    rv_y.append(-angle)\n",
    "        \n",
    "        return np.array(rv_x), np.array(rv_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss for driving in the mean direction is 0.06930196517655197\n"
     ]
    }
   ],
   "source": [
    "data_loader = DataLoader([\n",
    "    ('new_data/driving_straight', 1),\n",
    "    ('new_data/driving_straight_reverse_direction', 1),\n",
    "    ('new_data/driving_straight2', 1),\n",
    "#     ('new_data/jungle_track', 1),\n",
    "#     ('new_data/jungle_track_reverse_direction', 1),\n",
    "])\n",
    "\n",
    "x, y = data_loader.load_all_data()\n",
    "\n",
    "print('loss for driving in the mean direction is {}'.format(\n",
    "    np.mean((y - np.mean(y)) ** 2)\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18547 samples, validate on 4637 samples\n",
      "Epoch 1/7\n",
      "18528/18547 [============================>.] - ETA: 0s - loss: 0.0337Epoch 00001: val_loss improved from inf to 0.01300, saving model to model1_ckpt.h5\n",
      "18547/18547 [==============================] - 22s 1ms/step - loss: 0.0337 - val_loss: 0.0130\n",
      "Epoch 2/7\n",
      "18528/18547 [============================>.] - ETA: 0s - loss: 0.0156Epoch 00002: val_loss did not improve\n",
      "18547/18547 [==============================] - 22s 1ms/step - loss: 0.0156 - val_loss: 0.0138\n",
      "Epoch 3/7\n",
      "18528/18547 [============================>.] - ETA: 0s - loss: 1373.0376Epoch 00003: val_loss did not improve\n",
      "18547/18547 [==============================] - 22s 1ms/step - loss: 1371.6312 - val_loss: 0.1061\n",
      "Epoch 4/7\n",
      "18528/18547 [============================>.] - ETA: 0s - loss: 0.0940Epoch 00004: val_loss did not improve\n",
      "18547/18547 [==============================] - 22s 1ms/step - loss: 0.0940 - val_loss: 0.0839\n",
      "Epoch 5/7\n",
      "18528/18547 [============================>.] - ETA: 0s - loss: 0.0778Epoch 00005: val_loss did not improve\n",
      "18547/18547 [==============================] - 22s 1ms/step - loss: 0.0779 - val_loss: 0.0734\n",
      "Epoch 6/7\n",
      "18528/18547 [============================>.] - ETA: 0s - loss: 0.0713Epoch 00006: val_loss did not improve\n",
      "18547/18547 [==============================] - 22s 1ms/step - loss: 0.0713 - val_loss: 0.0700\n",
      "Epoch 7/7\n",
      "18528/18547 [============================>.] - ETA: 0s - loss: 0.0696Epoch 00007: val_loss did not improve\n",
      "18547/18547 [==============================] - 22s 1ms/step - loss: 0.0696 - val_loss: 0.0693\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, optimizers, callbacks\n",
    "\n",
    "EPOCHS = 7\n",
    "TOP_CROP = 70\n",
    "BOTTOM_CROP = 20\n",
    "\n",
    "# get repeatable results\n",
    "numpy.random.seed(42)\n",
    "tensorflow.set_random_seed(42)\n",
    "\n",
    "\n",
    "def nvidia_net():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Cropping2D(cropping=((TOP_CROP, BOTTOM_CROP), (0, 0)), input_shape=(160, 320, 3)))\n",
    "    model.add(layers.Lambda(lambda x: x / 255.0 - 0.5))\n",
    "    model.add(layers.Conv2D(24, (5, 5), strides=(2, 2), activation='elu'))\n",
    "    model.add(layers.Conv2D(36, (5, 5), strides=(2, 2), activation='elu'))\n",
    "    model.add(layers.Conv2D(48, (5, 5), strides=(2, 2), activation='elu'))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='elu'))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='elu'))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1164, activation='elu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(100, activation='elu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(50, activation='elu'))\n",
    "    model.add(layers.Dense(10, activation='elu'))\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "def lenet():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Cropping2D(cropping=((TOP_CROP, BOTTOM_CROP), (0, 0)), input_shape=(160, 320, 3)))\n",
    "    model.add(layers.Lambda(lambda x: x / 255.0 - 0.5))\n",
    "    model.add(layers.Conv2D(6, (5, 5), activation='elu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(16, (5, 5), activation='elu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='elu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(84))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "def single_layer_net():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Cropping2D(cropping=((TOP_CROP, BOTTOM_CROP), (0, 0)), input_shape=(160, 320, 3)))\n",
    "    model.add(layers.Lambda(lambda x: x / 255.0 - 0.5))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = nvidia_net()\n",
    "\n",
    "optimizer = optimizers.Adam() # lr=0.0001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='mse')\n",
    "\n",
    "checkpointer = callbacks.ModelCheckpoint(filepath='model1_ckpt.h5', verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(x, y, validation_split=0.2, epochs=EPOCHS, shuffle=True, callbacks=[checkpointer])\n",
    "\n",
    "model.save('model1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
